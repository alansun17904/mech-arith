\documentclass[10pt]{article}
\usepackage{stat}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage[margin=1.25in]{geometry}
\usepackage{natbib}
\usepackage{todonotes}
\usepackage{imakeidx}
\usepackage{wrapfig}
\bibliographystyle{plainnat}

\title{On \textit{Mechanistic Stability}, Generalization, and Robustness}
\date{\today}

\setlength\parindent{0pt}%
\setlength{\parskip}{3pt}%

\begin{document}

\ifthenelse{\isundefined{\showlinenum}}{
}{
\linenumbers
}
\maketitle

\begin{abstract}
Herein, we introduce a notion which we call \textit{mechanistic stability} which
characterizes the sensitivity of a models' prediction criteria with respect to
perturbations of the task specification.
\end{abstract}

{\fontfamily{lmss}
\begin{spacing}{1}
\tableofcontents
\end{spacing}
}
\clearpage
\setcounter{page}{1}

\allowdisplaybreaks

\input{sections/defs}

\section{Main results}
Herein, is a wish list of the main results that we wish to achieve.
\begin{thm}
Mechanistic stability $\Rightarrow$ in-distribution 
robustness, assuming that both $\cX, \cY$ are metric spaces. 
We also need that the task distribution $\cD_{\cX\times \cY}$ is smooth.
\end{thm}
\begin{thm}
Mechanistic stability $\Rightarrow$ in-distribution generalization.
\end{thm}
Maybe for proving this latter theorem, we can look at some proofs relating regularization.
What is a notion of in-distribution generalization that makes sense to look
at here. Can we say something stronger maybe? What about out-of-distribution?
like distribution shift?


\section{Related Literature}
What is the relationship between our notion of mechanistic stability and 
the more general notion of algorithmic stability? Is it potentially the same
as algorithmic stability applied to in-context learning?

\textbf{Algorithmic stability.} What is the relationship between algorithmic
stability and the notion of mechanistic stability that we are defining, both
in terms of the generalization bounds that are guaranteed with algorithmic
stability and in terms of the concept itself (how are we measuring
the distance between two learned hypotheses?)

\textbf{Mechanistic interpretability.} Recently, there has a been a push to interpret
neural networks by uncovering their
\textit{mechanisms}. A mechanism of a neural network with respect to some task
is a minimal subgraph of its computational graph that wholly characterizes the
network's behavior on this task~\citep{wang_interpretability_2022}. After exposing
the driving mechanisms 

A brief introduction to the field
and how our work provides rigorous guarantees for a lot of the work being
done in MI.

\textbf{Graphical models.} Probably need to rethink the title here, we want
to explain the relationship between directed acyclic graphs, causal graphs,
and the mechanisms that we are extracting from the neural network. Our
underlying assumption is that all of these things are the same.

\section{Experimental Methods}
Can we show mechanistic stability and instability on a host of tasks?
\begin{enumerate}
\item IOI
\item Colored Objects
\item Arithmetic
\item General algorithmic tasks
\item General reasoning tasks (this and the previous task would benefit
from increased test time compute and enhanced supervision; so we can we
somehow increase stability by increasing one of these factors?)
\item General knowledge tasks (would not benefit from chain-of-thought or more
test time compute)
\end{enumerate}
What is the effect of scale on mechanistic stability? Or conversely, the benefits
that we see in terms of performance as a result of increased scale, does this
come from increased mechanistic stability?


\bibliography{references}

\newpage
\section{Category-Theoretic Causality}

\end{document}
