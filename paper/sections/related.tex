% !TEX root = ../main.tex

\section{Related Literature}
There have been extensive studies separately on notions of stability for
deep neural networks, mechanistic interpretability, and causal equivalence.
In this section, we provide a brief review of these subfields as they
relate to our contributions. In particular, we seek to show that our notion
of \textit{mechanistic stability} is a culmination of the works in these areas.

\textbf{Algorithmic stability.} What is the relationship between algorithmic
stability and the notion of mechanistic stability that we are defining, both
in terms of the generalization bounds that are guaranteed with algorithmic
stability and in terms of the concept itself (how are we measuring
the distance between two learned hypotheses?)

\textbf{Causal equivalence.} 

\textbf{Mechanistic interpretability.} Recently, there has a been a push to interpret
neural networks by uncovering their
\textit{mechanisms}. A mechanism of a neural network with respect to some task
is a minimal subgraph of its computational graph that wholly characterizes the
network's behavior on this task~\citep{wang_interpretability_2022}. After exposing
the driving mechanisms 
